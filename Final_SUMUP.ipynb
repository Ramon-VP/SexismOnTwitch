{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rsrgqGNQ8w1y",
        "lkrloc9nIwqy",
        "vRBAc7VuWoy8",
        "FRQ8yTNiWuNz",
        "bfW4ZHuHFVwv",
        "kL5KuE2sA1DL"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qch_uFvOoQa-"
      },
      "source": [
        "#### Initialize Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHusJs-g-d71"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "import itertools\n",
        "\n",
        "!pip install fasttext\n",
        "import fasttext\n",
        "\n",
        "data_path = ''\n",
        "import nest_asyncio\n",
        "from twitchio.ext import commands\n",
        "from twitchio.abcs import Messageable\n",
        "\n",
        "data_path = 'Data/'\n",
        "results_path = 'Results/'\n",
        "dataset_path = data_path+'Datasets/'\n",
        "train_path = data_path+'Train/'\n",
        "test_path = data_path+'Test/'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsrgqGNQ8w1y"
      },
      "source": [
        "#### Auxiliar functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2r-YcGQKtRB",
        "outputId": "cc3e6554-b929-4c5d-d812-bd098c42c97a"
      },
      "source": [
        "def repeated_chars(word):\n",
        "    clean_word=\"\"\n",
        "    for _, dups in (itertools.groupby(word)):\n",
        "        seq = list(dups)\n",
        "        clean_word += seq[0]\n",
        "        if len(seq)>1:\n",
        "            clean_word += seq[1]\n",
        "    return clean_word\n",
        "\n",
        "def cleanComment(comment):\n",
        "    stemming = PorterStemmer()\n",
        "    stops = set(stopwords.words(\"spanish\"))\n",
        "    ## START CODE\n",
        "    line= comment.lower() ## Transform in lowercase\n",
        "    line=re.sub('[:\\[\\]&%$\\\"\\'!./,;:?=¿^\\-#_*+)<>(¡@]','',line)\n",
        "    line= line.split() ## Tokenize the text to get a list of terms\n",
        "    line= [repeated_chars(word) for word in line]\n",
        "    #line= [word for word in line if word not in stops]  ##eliminate the stopwords (HINT: use List Comprehension)\n",
        "    line= [stemming.stem(word) for word in line] ## perform stemming (HINT: use List Comprehension)\n",
        "    ## END CODE\n",
        "    cleanedComment = \"\"\n",
        "    for i, word in enumerate(line):\n",
        "      if i!=0:\n",
        "        cleanedComment += \" \"\n",
        "      cleanedComment += word\n",
        "    return cleanedComment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no pero tien culazo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxyVBarhA6-8"
      },
      "source": [
        "## FASTTEXT "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkrloc9nIwqy"
      },
      "source": [
        "#### Read Categorized Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0P_5GxlOGnGi"
      },
      "source": [
        "fp = open(train_path+\"Chat_Training_Model1.txt\", \"r\", encoding=\"utf-8\")    \n",
        "other_comments = list()\n",
        "\n",
        "line = fp.readline()\n",
        "while(len(line) != 0):\n",
        "    if \"__label__0\" in line:\n",
        "        other_comments.append(line[len(\"__label__0\"):])\n",
        "    line = fp.readline()\n",
        "fp.close()\n",
        "\n",
        "\n",
        "fp = open(train_path+\"Chat_Training_Model2.txt\", \"r\", encoding=\"utf-8\")\n",
        "inappropriate_comments = list()\n",
        "sexist_comments = list()\n",
        "\n",
        "line = fp.readline()\n",
        "while(len(line) != 0):\n",
        "    if \"__label__0\" in line:\n",
        "        inappropriate_comments.append(line[len(\"__label__0\"):])\n",
        "    elif \"__label__1\" in line:\n",
        "        sexist_comments.append(line[len(\"__label__1\"):])\n",
        "    line = fp.readline()\n",
        "fp.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRBAc7VuWoy8"
      },
      "source": [
        "##### Sexist Comments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXvvpiLnKfx3"
      },
      "source": [
        "print(\"Number of sexist comments: \",len(sexist_comments))\n",
        "print(\"Corresponds to a\",len(sexist_comments)/(len(sexist_comments)+len(inappropriate_comments)+len(other_comments)),\"% of the comments in the file.\\n\")\n",
        "for comment in sexist_comments:\n",
        "  print(comment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRQ8yTNiWuNz"
      },
      "source": [
        "##### Inappropiate Comments\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce1-G7j1L3Ax"
      },
      "source": [
        "print(\"Number of inappropiate comments: \",len(inappropriate_comments))\n",
        "print(\"Corresponds to a\",len(inappropriate_comments)/(len(sexist_comments)+len(inappropriate_comments)+len(other_comments)),\"% of the comments in the file.\\n\")\n",
        "for comment in inappropriate_comments:\n",
        "  print(comment)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x2qhv2XoIYr"
      },
      "source": [
        "#### FastText model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo9TK_VELevx"
      },
      "source": [
        "##### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23EyJL2roOZE"
      },
      "source": [
        "hyper_params = {\"lr\": 0.01,\n",
        "    \"epoch\": 200,\n",
        "    \"wordNgrams\": 2}  \n",
        "\n",
        "model = fasttext.train_supervised(input=train_path+\"Chat_Training_Model1.txt\", **hyper_params)\n",
        "model.save_model(results_path+\"model1.bin\")\n",
        "\n",
        "model = fasttext.train_supervised(input=train_path+\"Chat_Training_Model2.txt\", **hyper_params)\n",
        "model.save_model(results_path+\"model2.bin\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "smZUMspaFJT7"
      },
      "source": [
        "##### Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQtkZZSr-fLd"
      },
      "source": [
        "model = fasttext.load_model(results_path+\"model2.bin\")\n",
        "model.test(test_path+\"Chat_Testing_Model2.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfW4ZHuHFVwv"
      },
      "source": [
        "#### Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kGnHIvEoRt9-"
      },
      "source": [
        "model = fasttext.load_model(results_path+\"model1.bin\")\n",
        "model.predict(cleanComment(\"te gusta el sado o mas de chill\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL5KuE2sA1DL"
      },
      "source": [
        "## TWITCH BOT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S93OkklTA0cr",
        "outputId": "95017bef-8aa6-417a-8b60-bad6ac14a08e"
      },
      "source": [
        "text_file = open(dataset_path+\"paraules_prohibides.txt\", \"r\",encoding='utf-8')\n",
        "paraules_prohibides= list()\n",
        "comentaris=list()\n",
        "frase=text_file.readline()\n",
        "\n",
        "while(len(frase) != 0):\n",
        "    frase2=frase.split(\"\\n\")\n",
        "    paraules_prohibides.append(frase2[0])\n",
        "    frase = text_file.readline()\n",
        "text_file.close()\n",
        "\n",
        "#inicialitzacio de les llistes necessaries pel bot\n",
        "primer_warning=list()\n",
        "segon_warning=list()\n",
        "primer_baboso=list()\n",
        "segon_baboso=list()\n",
        "ban=list()\n",
        "model = fasttext.load_model(\"results\\model1.bin\")\n",
        "model2 = fasttext.load_model(\"results\\model2.bin\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrW35fDIB8_2"
      },
      "source": [
        "### Bot Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dynGHpDUB4Da"
      },
      "source": [
        "class Bot(commands.Bot):\n",
        "    def __init__(self):\n",
        "        nick = \"\"\n",
        "        chanel = \"\"\n",
        "        with open(\"config.secret\",\"r\") as fp:\n",
        "            lines = fp.readlines()\n",
        "            config = {}\n",
        "            for line in lines:\n",
        "                partes = line.replace(\"\\n\",\"\").split(\"=\")\n",
        "                config[partes[0]] = partes[1]\n",
        "            super().__init__(\n",
        "                irc_token=config['TOKEN'],\n",
        "                client_id =config['CLIENT_ID'],\n",
        "                nick=config['BOT_NICK'],\n",
        "                prefix=config['BOT_PREFIX'],\n",
        "                initial_channels=[config['CHANNEL']]\n",
        "            )\n",
        "            self.nick = config['BOT_NICK']\n",
        "            self.channel = config['CHANNEL']\n",
        "            \n",
        "    async def event_ready(self):\n",
        "        print(f'Listo! | {self.nick}')\n",
        "        ws = self._ws \n",
        "        await ws.send_privmsg(self.channel, f\"/me has landed!\")\n",
        "    \n",
        "  \n",
        "    async def event_message(self, message):\n",
        "        ban=0\n",
        "        print(message.content)\n",
        "        print(message.author.name)\n",
        "        mensage_final_clean= cleanComment(message.content)\n",
        "        #primer filtre\n",
        "        mensage_final=mensage_final_clean.split()\n",
        "        for mes in mensage_final:\n",
        "            if(mes in paraules_prohibides ):\n",
        "                ban=1\n",
        "                ws = self._ws\n",
        "\n",
        "                channel= self.channel\n",
        "\n",
        "                #await ws.send_privmsg(channel, f\".slow\")\n",
        "                if(message.author.name in primer_warning):\n",
        "                    segon_warning.append(message.author.name)\n",
        "                    primer_warning.remove(message.author.name)\n",
        "                    \n",
        "\n",
        "                    await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 120\")\n",
        "                    \n",
        "                elif (message.author.name in segon_warning):\n",
        "                    segon_warning.remove(message.author.name)\n",
        "                    ban.append(message.author.name)\n",
        "                    await ws.send_privmsg(channel, f\".ban \"+ message.author.name )\n",
        "                else:\n",
        "                    primer_warning.append(message.author.name)\n",
        "                    await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 60\")\n",
        "                #await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 60\")\n",
        "\n",
        "                comentaris_prohibits.append(message.content)\n",
        "                \n",
        "                break\n",
        "        #segon filtre \n",
        "        print(\"llega\")\n",
        "        if(ban==0):\n",
        "            ws = self._ws\n",
        "            channel= self.channel\n",
        "            print(mensage_final_clean)\n",
        "            print(model.predict(mensage_final_clean))\n",
        "            if(model.predict(mensage_final_clean)[0][0] =='__label__1' ):\n",
        "                print(model2.predict(mensage_final_clean))\n",
        "                if(model2.predict(mensage_final_clean)[0][0] =='__label__1' ):\n",
        "                    if(message.author.name in primer_warning):\n",
        "                        segon_warning.append(message.author.name)\n",
        "                        primer_warning.remove(message.author.name)\n",
        "                        await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 120\")\n",
        "                    elif (message.author.name in segon_warning):\n",
        "                        segon_warning.remove(message.author.name)\n",
        "                        ban.append(message.author.name)\n",
        "                        await ws.send_privmsg(channel, f\".ban \"+ message.author.name )\n",
        "                    else:\n",
        "                        primer_warning.append(message.author.name)\n",
        "                        await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 60\")\n",
        "                else:\n",
        "                    \n",
        "                    if(message.author.name in primer_baboso):\n",
        "                        segon_baboso.append(message.author.name)\n",
        "                        primer_baboso.remove(message.author.name)\n",
        "                        await ws.send_privmsg(self.channel, f\" \" +message.author.name +\" be careful my friend! \")\n",
        "\n",
        "                    elif (message.author.name in segon_baboso):\n",
        "                        segon_baboso.remove(message.author.name)\n",
        "                        await ws.send_privmsg(channel, f\".timeout \"+ message.author.name +\" 60\")\n",
        "                    else:\n",
        "                        primer_baboso.append(message.author.name)\n",
        "                        await ws.send_privmsg(self.channel, f\" \" +message.author.name +\" be careful my friend! \")\n",
        "        \n",
        "    # Decorador para los comandos\n",
        "    @commands.command(name='saludo')\n",
        "    async def saludo(self, ctx):\n",
        "        await ctx.send(f'Hola {ctx.author.name}!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMNtB5Hrx7v9"
      },
      "source": [
        "nest_asyncio.apply()\n",
        "bot = Bot()\n",
        "\n",
        "bot.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}